# -*- coding: utf-8 -*-
"""Prototype d'Extracteur de Caractéristiques de Documents Juridiques

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14kJNw71kz_z1fQTy3ibLzz952YhS9_-3
"""

!pip install pytesseract

!pip install ArabicOcr

!pip install tesseract

!apt install tesseract-ocr
!apt install libtesseract-dev
!apt install tesseract-ocr-ara

"""**Les bibliothèques nécessaires**"""

from ArabicOcr import arabicocr
import pytesseract
from pytesseract import Output
from PIL import Image ,ImageOps ,ImageFilter , ImageDraw
import cv2
from google.colab.patches import cv2_imshow
import nltk
from nltk.data import find
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import string
from pytesseract import get_tesseract_version
import os
import re

"""**Prétraitement de l'image**"""

image1 = Image.open('image 1.jpg')

#check image load
if image1 is None:
    print("Impossible de charger l'image.")
else:
  print("true")

image1

# Conversion en niveaux de gris
imageGris = image1.convert("L")
imageGris

# Amélioration du contraste
image_contraste_ameliore = ImageOps.equalize(imageGris)
image_contraste_ameliore

# Appliquer un filtre de lissage moyen pour atténuer le bruit
image_sans_bruit = imageGris.filter(ImageFilter.MedianFilter(size=3))
image_sans_bruit

##Installation of training data for Arabic language
# Check Tesseract version installed
print("Version de Tesseract installée:", get_tesseract_version())

# Specify the directory where to store Tesseract training data
tessdata_dir_config = '--tessdata-dir "/chemin/vers/tessdata"'

# Download and install training data for Arabic language
os.system(f"wget -P /chemin/vers/tessdata https://github.com/tesseract-ocr/tessdata/raw/main/ara.traineddata")
os.system(f"mv /chemin/vers/tessdata/ara.traineddata /chemin/vers/tessdata/ara.traineddata")

# Check if training data has been installed correctly
if os.path.exists("/chemin/vers/tessdata/ara.traineddata"):
    print("Données de formation pour la langue arabe installées avec succès.")
else:
    print("Erreur lors de l'installation des données de formation pour la langue arabe.")

"""**Extraction du texte**"""

texte = pytesseract.image_to_string(image_sans_bruit, lang='ara')
texte

"""**Traitement du texte**"""

# Load stopwords in Arabic
stop_words = set(stopwords.words('arabic'))

# Tokenize the text into sentences
sentences = sent_tokenize(texte)

# Define a function to preprocess each sentence
def preprocess(sentence):
  # Tokenize the sentence into words
  words= nltk.word_tokenize(sentence)

  # Remove stopwords and punctuation
  words_filtered = [word.lower() for word in words if word.lower() not in stop_words and word not in string.punctuation]

  return words

# Preprocess each sentence in the text
T_clean = [preprocess(sentence) for sentence in sentences]
T_clean

"""**Extraction des caractéristiques et de formatage de sortie**"""

def extraire_caracteristiques(texte):
    # Initialiser les dictionnaires pour stocker les caractéristiques extraites
    caractéristiques = {
        "Type de Document": [],
        "Dates": [],
        "Parties Impliquées": [],
        "Termes Clés": [],
        "Éléments d'Action": [],
        "Les sujet": []
    }

    # Modèles de regex pour chaque caractéristique
    motifs = {
        "Type de Document": r"Type\s+de\s+Document\s*:\s*(.+)",
        "Dates": r"Dates\s*:\s*(.+)",
        "Parties Impliquées": r"Parties\s+Impliquées\s*:\s*(.+)",
        "Termes Clés": r"Termes\s+Clés\s*:\s*(.+)",
        "Éléments d'Action": r"Éléments\s+d'Action\s*:\s*(.+)",
        "Les sujet": r"Les\s+sujet\s*:\s*(.+)"
    }

    # Parcourir chaque caractéristique et extraire les correspondances
    for caractéristique, motif in motifs.items():
        correspondances = re.findall(motif, texte, re.IGNORECASE)
        if correspondances:
            caractéristiques[caractéristique] = [c.strip() for c in correspondances]

    return caractéristiques



# Extraire les caractéristiques du texte d'exemple
caractéristiques_extraites = extraire_caracteristiques(texte)

# Afficher les caractéristiques extraites
for caractéristique, valeurs in caractéristiques_extraites.items():
    print(caractéristique + ":")
    for valeur in valeurs:
        print("-", valeur)

"""**Interface en ligne de commande**"""

def main():
    # Clear the console screen
    os.system('cls' if os.name == 'nt' else 'clear')

    print("Bienvenue dans l'outil d'extraction de texte !")
    print("Veuillez entrer le chemin vers le document numérisé :")

    # Ask user to enter image path
    image_path = input("entrez le chemin de l’image")

    # Check if file exists
    if not os.path.exists(image_path):
        print("Le fichier spécifié n'existe pas.")
        return

    # Extract text from document
    texte_extrait = extract_text(image_path)

    # Display extracted text
    print("\nTexte extrait du document :")
    print(texte_extrait)

if __name__ == "__main__":
    main()

